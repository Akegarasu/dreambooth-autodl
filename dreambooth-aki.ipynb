{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0b34c19-4215-46f9-9def-65e73629665c",
   "metadata": {},
   "source": [
    "# Dreambooth Stable Diffusion 一键训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da847853-7fd5-4ca2-ab72-13d5885e99bd",
   "metadata": {},
   "source": [
    "## 相关说明\n",
    "\n",
    "详细使用教程[bilibili 秋葉aaaki](https://space.bilibili.com/12566101)\n",
    "\n",
    "修改自 [Nyanko Lepsoni 的 Colab 笔记本](https://colab.research.google.com/drive/17yM4mlPVOFdJE_81oWBz5mXH9cxvhmz8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa154e14-e812-4604-8980-9762e9563b32",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 准备全局变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2260f499-85cf-481e-b7a3-97bc212ff956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "py310 = sys.executable\n",
    "\n",
    "!$py310 --version\n",
    "%cd /root/autodl-tmp/dreambooth-aki\n",
    "\n",
    "TRAINER = \"train_dreambooth.py\"\n",
    "CONVERTER = \"convert_v2.py\"\n",
    "BACK_CONVERTER = \"back_convert.py\"\n",
    "ACCELERATE_BIN = \"/root/miniconda3/envs/diffusers/bin/accelerate\"\n",
    "\n",
    "SRC_PATH = \"./model-sd\"\n",
    "MODEL_NAME = \"./model-hf\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def72b19-9851-400f-8672-48023b3e95fb",
   "metadata": {},
   "source": [
    "## 转换ckpt文件\n",
    "\n",
    "镜像里，我已经帮你转换好了final-prune这个模型。并且镜像为了节省空间，并没有自带未转换的模型。\n",
    "**如果有model-hf这个文件夹，那就不需要运行这个转换模型了。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92e663d-7cf1-408e-911b-22270ac8a388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这步骤有些慢，没准要等个几分钟\n",
    "vae_arg = f\"--vae_path {SRC_PATH}/animevae.pt\"\n",
    "!$py310 $CONVERTER --checkpoint_path $SRC_PATH/model.ckpt --original_config_file $SRC_PATH/config.yaml $vae_arg --dump_path $MODEL_NAME --scheduler_type ddim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746137f4-b054-43de-a2d1-6ebde5cdb3aa",
   "metadata": {},
   "source": [
    "## 配置dreambooth训练提示词"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0645e79-84f5-491e-8fba-25900beb7c7b",
   "metadata": {},
   "source": [
    "以训练人物为例，\n",
    "\n",
    "INSTANCE_PROMPT 中填入 masterpiece, best quality, bocchitherock girl\n",
    "这个bocchitherock需要你自己替换为要训练的tag名。你可以指定任意tag，但是需要找一个“不存在的词”。这里的bocchitherock是我做示范用的训练“孤独摇滚”中人物写的一个tag。\n",
    "注意：不要再用别的教程里的**sks**了，这个sks是一把枪的名字，可能会生成的时候带上这把枪\n",
    "\n",
    "CLASS_PROMPT 是让AI自动生成class image用的tag。复制一份INSTANCE_PROMPT，删掉你学习的tag即可。比如这里删掉了bocchitherock\n",
    "\n",
    "同理，下面的预览图tag设置也记得改。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e425bf69-1427-4f5a-858c-f0e36a42518d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANCE_PROMPT\n",
    "INSTANCE_PROMPT = \"masterpiece, best quality, bocchitherock 1girl\"\n",
    "INSTANCE_DIR = \"./instance-images\"\n",
    "\n",
    "# class image 设置\n",
    "CLASS_PROMPT = \"masterpiece, best quality, 1girl\"\n",
    "CLASS_NEGATIVE_PROMPT = \"lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry\"\n",
    "CLASS_DIR = \"./class-images\"\n",
    "\n",
    "# 预览图tag设置\n",
    "SAVE_SAMPLE_PROMPT = \"masterpiece, best quality, bocchitherock 1girl, looking at viewer\"\n",
    "SAVE_SAMPLE_NEGATIVE_PROMPT = \"lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry\"\n",
    "\n",
    "# 模型保存路径\n",
    "OUTPUT_DIR = \"./output\"\n",
    "print(f\"[*] 模型将会保存在这个路径 {OUTPUT_DIR}\")\n",
    "!mkdir -p $OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e7d7e3-35dc-4f8e-b444-0705556c67fa",
   "metadata": {},
   "source": [
    "## 训练数据可视化\n",
    "\n",
    "这里预留了 wandb 和 tensorboard 的可视化。如果你不知道这是什么，就不要改了，直接点运行即可。我已经默认打开了tensorboard。\n",
    "如果你会用 wandb，那么可以填写apikey并且将`use_wandb`改为`True`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b489a6-eff7-42ff-80f6-823457c097d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_tensorboard = True \n",
    "use_wandb = False\n",
    "save_weights_to_wandb = False\n",
    "wandb_apikey = \"\"\n",
    "\n",
    "if use_wandb:\n",
    "  if wandb_apikey == \"\":\n",
    "    raise ValueError('Invalid wandb.ai APIKey')\n",
    "  !$py310 -m wandb login $wandb_apikey\n",
    "\n",
    "if use_tensorboard:\n",
    "  !rm -rf /tmp/.tensorboard-info/\n",
    "  %load_ext tensorboard\n",
    "  %tensorboard --logdir $OUTPUT_DIR/logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fa5cd8-b393-4e0c-af88-72677e29830c",
   "metadata": {},
   "source": [
    "## 配置accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe981666-70d3-4f2d-b51a-969e12911a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!./accelerate.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327eac82-bc9f-4da5-89b6-5362d26fc72b",
   "metadata": {},
   "source": [
    "## 设置训练参数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0859292-f678-4ec1-aa67-4143a8f7f8e2",
   "metadata": {},
   "source": [
    "### max_train_steps\n",
    "训练步数\n",
    "\n",
    "### learning_rate\n",
    "学习率\n",
    "这里设置的5e-6是科学计数法的(5乘以10的-6次方)。一般就用这个值就可以了，有时候这个默认值有点大，可以小一些比如3e-6。如果你还是觉得太大可以缩小到1e-6、甚至是5e-7等等。\n",
    "\n",
    "### lr_scheduler\n",
    "学习率调整策略\n",
    "一般lr_scheduler就用cosine、cosine_with_restarts就可以了。\n",
    "想了解更多关于lr_scheduler可以看看这个[知乎](https://www.zhihu.com/question/315772308/answer/2384958925)\n",
    "\n",
    "### batch_size\n",
    "一般是1。我推荐不要超过3。调整batch_size需要同时调整学习率\n",
    "详情参考我的视频[BV1A8411775m](https://www.bilibili.com/video/BV1A8411775m/)\n",
    "\n",
    "### num_class_images\n",
    "class image的数量。如果class-images文件夹内的图片数量小于这个值，则会AI自动生成一些图片。\n",
    "如果关闭了下面的with_prior_preservation，那么这个参数就没用了。\n",
    "\n",
    "### with_prior_preservation\n",
    "关闭了这个参数以后，训练将不会再用class images，变为native training。训练画风需要关闭\n",
    "\n",
    "更深入的细节可以参考这个[stable-diffusion-book](https://stable-diffusion-book.vercel.app/train/DreamBooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b39775a-9bb6-4f4e-be84-d0558d25befc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 常用参数\n",
    "## 最大训练步数\n",
    "max_train_steps = 3000\n",
    "## 学习率调整\n",
    "learning_rate = 5e-6\n",
    "## 学习率调整策略\n",
    "## [\"linear\", \"cosine\", \"cosine_with_restarts\", \"polynomial\", \"constant\", \"constant_with_warmup\", \"cosine_with_restarts_mod\", \"cosine_mod\"]\n",
    "lr_scheduler = \"cosine_with_restarts\"\n",
    "lr_warmup_steps = 100\n",
    "# batch_size\n",
    "train_batch_size = 1\n",
    "# class_images 数量\n",
    "num_class_images = 20\n",
    "\n",
    "with_prior_preservation = True\n",
    "\n",
    "# 从文件名读取 prompt\n",
    "read_prompt_from_filename = False\n",
    "# 从 txt 读取prompt\n",
    "read_prompt_from_txt = False\n",
    "append_prompt = \"instance\"\n",
    "# 保存间隔\n",
    "save_interval = 500\n",
    "# 使用deepdanbooru\n",
    "use_deepdanbooru = False\n",
    "\n",
    "# 高级参数\n",
    "resolution = 512\n",
    "gradient_accumulation_steps = 1\n",
    "seed = 1337\n",
    "log_interval = 10\n",
    "clip_skip = 1\n",
    "sample_batch_size = 4\n",
    "prior_loss_weight = 1.0\n",
    "use_aspect_ratio_bucket = False\n",
    "scale_lr = False\n",
    "scale_lr_sqrt = False\n",
    "gradient_checkpointing = True\n",
    "pad_tokens = False\n",
    "debug_arb = False\n",
    "debug_prompt = False\n",
    "use_ema = False\n",
    "train_text_encoder = False\n",
    "#only works with _mod scheduler\n",
    "restart_cycle = 1\n",
    "last_epoch = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fe1929-395e-4175-97b7-096b8c1133ee",
   "metadata": {},
   "source": [
    "## 从中途继续训练，需要运行下面这个\n",
    "\n",
    "如果是继续训练就更改这个路径到想继续训练的模型文件夹然后运行这个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c1da3b-c6f2-4312-98a5-dea2dd73c8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"./output/checkpoint_last\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6845fc-799f-455e-a723-6fa68e7cb523",
   "metadata": {},
   "source": [
    "## 启动训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fe6d54-783b-4f7b-86ae-3be589e3c718",
   "metadata": {},
   "outputs": [],
   "source": [
    "ema_arg = \"--use_ema\" if use_ema else \"\"\n",
    "da_arg = \"--debug_arb\" if debug_arb else \"\"\n",
    "db_arg = \"--debug_prompt\" if debug_prompt else \"\"\n",
    "pd_arg = \"--pad_tokens\" if pad_tokens else \"\"\n",
    "gdc_arg = \"--gradient_checkpointing\" if gradient_checkpointing else \"\"\n",
    "dp_arg = \"--deepdanbooru\" if use_deepdanbooru else \"\" \n",
    "scale_lr_arg = \"--scale_lr\" if scale_lr else \"\"\n",
    "wandb_arg = \"--wandb\" if use_wandb else \"\"\n",
    "extra_prompt_arg = \"--read_prompt_txt\" if read_prompt_from_txt else \"\"\n",
    "arb_arg = \"--use_aspect_ratio_bucket\" if use_aspect_ratio_bucket else \"\"\n",
    "tte_arg = \"--train_text_encoder\" if train_text_encoder else \"\"\n",
    "ppl_arg = f\"--with_prior_preservation --prior_loss_weight={prior_loss_weight}\" if with_prior_preservation else \"\"\n",
    "\n",
    "if scale_lr_sqrt:\n",
    "  scale_lr_arg = \"--scale_lr_sqrt\"\n",
    "\n",
    "if read_prompt_from_filename:\n",
    "  extra_prompt_arg = \"--read_prompt_filename\"\n",
    "\n",
    "if save_weights_to_wandb:\n",
    "  wandb_arg = \"--wandb --wandb_artifact\"\n",
    "\n",
    "%cd /root/autodl-tmp/dreambooth-aki\n",
    "!mkdir -p $OUTPUT_DIR\n",
    "\n",
    "!$ACCELERATE_BIN launch $TRAINER \\\n",
    "  --mixed_precision=\"fp16\" \\\n",
    "  --pretrained_model_name_or_path=$MODEL_NAME \\\n",
    "  --instance_data_dir=$INSTANCE_DIR \\\n",
    "  --class_data_dir=$CLASS_DIR \\\n",
    "  --output_dir=$OUTPUT_DIR \\\n",
    "  --instance_prompt=\"{INSTANCE_PROMPT}\" \\\n",
    "  --class_prompt=\"{CLASS_PROMPT}\" \\\n",
    "  --class_negative_prompt=\"{CLASS_NEGATIVE_PROMPT}\" \\\n",
    "  --save_sample_prompt=\"{SAVE_SAMPLE_PROMPT}\" \\\n",
    "  --save_sample_negative_prompt=\"{SAVE_SAMPLE_NEGATIVE_PROMPT}\" \\\n",
    "  --seed=$seed \\\n",
    "  --resolution=$resolution \\\n",
    "  --train_batch_size=$train_batch_size \\\n",
    "  --gradient_accumulation_steps=$gradient_accumulation_steps \\\n",
    "  --learning_rate=$learning_rate \\\n",
    "  --lr_scheduler=$lr_scheduler \\\n",
    "  --lr_warmup_steps=$lr_warmup_steps \\\n",
    "  --num_class_images=$num_class_images \\\n",
    "  --sample_batch_size=$sample_batch_size \\\n",
    "  --max_train_steps=$max_train_steps \\\n",
    "  --save_interval=$save_interval \\\n",
    "  --log_interval=$log_interval \\\n",
    "  --clip_skip $clip_skip \\\n",
    "  --num_cycle=$restart_cycle \\\n",
    "  --last_epoch=$last_epoch \\\n",
    "  --append_prompt=$append_prompt \\\n",
    "  --use_8bit_adam $da_arg $db_arg $ema_arg \\\n",
    "  $ppl_arg $wandb_arg $extra_prompt_arg $gdc_arg $arb_arg $tte_arg $scale_lr_arg $dp_arg $pd_arg\n",
    "\n",
    "# disabled: --not_cache_latents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6ffa47-7a1b-43aa-b3c9-4570a7de3c1c",
   "metadata": {},
   "source": [
    "## 转换训练好的模型到ckpt文件\n",
    "\n",
    "这里需要你修改model_folder_name, 比如\n",
    "checkpoint_1000\n",
    "checkpoint_2000\n",
    "想转换哪个模型写哪个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf319a13-7e00-4d38-9e91-e50302a3f5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder_name = \"checkpoint_last\"\n",
    "convert_model_path = f\"output/{model_folder_name}\"\n",
    "ckpt_path = f'{convert_model_path}/model.ckpt'\n",
    "save_half = True\n",
    "use_alt = False\n",
    "\n",
    "ckpt_convert_half_arg = \"--half\" if save_half else \"\"\n",
    "back_converter_arg = \"back_convert_alt.py\" if use_alt else \"back_convert.py\"\n",
    "\n",
    "!$py310 $back_converter_arg --model_path $convert_model_path --checkpoint_path $ckpt_path $ckpt_convert_half_arg\n",
    "print(f\"[*] 转换的模型保存在如下路径 {ckpt_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdea851b-750e-4d01-9794-9521a85a13d0",
   "metadata": {},
   "source": [
    "# 打开生成图像界面测试用\n",
    "\n",
    "**生成效果与本地webui不太一样，仅供参考**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e76ef0d-7130-4f11-8086-1d1349db91a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torch import autocast\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "use_checkpoint = 'checkpoint_last'\n",
    "ckpt_model_path = os.path.join(OUTPUT_DIR, use_checkpoint)\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(ckpt_model_path, torch_dtype=torch.float16).to(\"cuda\")\n",
    "g_cuda = None\n",
    "\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "def inference(prompt, negative_prompt, num_samples, height=512, width=512, num_inference_steps=50, guidance_scale=7.5):\n",
    "    with torch.autocast(\"cuda\"), torch.inference_mode():\n",
    "        return pipe(\n",
    "                prompt, height=int(height), width=int(width),\n",
    "                negative_prompt=negative_prompt,\n",
    "                num_images_per_prompt=int(num_samples),\n",
    "                num_inference_steps=int(num_inference_steps), guidance_scale=guidance_scale,\n",
    "                generator=g_cuda\n",
    "            ).images\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            prompt = gr.Textbox(label=\"tag\", value=\"masterpiece, best quality,\")\n",
    "            negative_prompt = gr.Textbox(label=\"负面tag\", value=\"lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry\")\n",
    "            num_inference_steps = gr.Slider(label=\"Steps\", value=28)\n",
    "            with gr.Row():\n",
    "                width = gr.Slider(minimum=64, maximum=2048, step=64, label=\"宽\", value=512)\n",
    "                height = gr.Slider(minimum=64, maximum=2048, step=64, label=\"高\", value=512)\n",
    "            with gr.Row():\n",
    "                num_samples = gr.Number(label=\"批量\", value=1)\n",
    "                guidance_scale = gr.Number(label=\"Guidance Scale\", value=7)\n",
    "\n",
    "        with gr.Column():\n",
    "            run = gr.Button(value=\"生成\")\n",
    "            gallery = gr.Gallery()\n",
    "\n",
    "    run.click(inference, inputs=[prompt, negative_prompt, num_samples, height, width, num_inference_steps, guidance_scale], outputs=gallery)\n",
    "\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ca52f9-83fc-4a4b-8589-3f6ee31ef69a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusers",
   "language": "python",
   "name": "diffusers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
